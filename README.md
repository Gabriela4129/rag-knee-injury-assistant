# Knee Injury RAG Assistant

A Retrieval-Augmented Generation (RAG) system that assists with knee injury questions (ACL tears, meniscus injuries, rehabilitation, return-to-sport, and knee osteoarthritis).

---

# ğŸš€ Features
- Local LLM inference via **Ollama (Llama 3)**
- Vector retrieval using **ChromaDB**
- Embeddings via **all-MiniLM-L6-v2**
- Three prompt versions (zero-shot, structured, chain-of-thought)
- Evaluation pipeline (latency, tokens, cost)
- CLI-based assistant with citations

---

# ğŸ“ Project Structure

rag-knee-injury-assistant/â€¨â”‚â€¨â”œâ”€â”€ data/raw/ # PDF documents (11 clinical sources)â€¨â”œâ”€â”€ chroma_db/ # Local vector storeâ€¨â”‚â€¨â”œâ”€â”€ src/â€¨â”‚ â”œâ”€â”€ ingest.py # PDF ingestion + chunking + embeddingsâ€¨â”‚ â”œâ”€â”€ rag_pipeline.py # Retrieval + LLM + promptsâ€¨â”‚ â”œâ”€â”€ cli.py # Interactive assistantâ€¨â”‚ â”œâ”€â”€ evaluate.py # Evaluation across 3 prompt versionsâ€¨â”‚â€¨â”œâ”€â”€ docs/â€¨â”‚ â”œâ”€â”€ DATA_SOURCES.mdâ€¨â”‚ â”œâ”€â”€ PROMPTS.mdâ€¨â”‚ â”œâ”€â”€ EVALUATION.mdâ€¨â”‚ â”œâ”€â”€ PRODUCTION.mdâ€¨â”‚â€¨â”œâ”€â”€ .env # Ollama config + chunk settingsâ€¨â”œâ”€â”€ requirements.txtâ€¨â””â”€â”€ README.md
---

# âš™ï¸ Quickstart

### 1. Install dependencies
```bash
pip install -r requirements.txt
2. Ensure Ollama is running
Download Ollama from: https://ollama.com
Start the model:
ollama run llama3
3. Ingest PDFs
Place your clinical PDFs inside:
data/raw/
Run ingestion:
python src/ingest.py
4. Start the CLI assistant
python src/cli.py
5. Run evaluation
python src/evaluate.py
This generates:
* results/eval_raw.json
* results/eval_summary.csv

ğŸ“š Dataset
The system uses 11 clinical PDF documents, covering:
* ACL diagnosis & physical tests
* ACL reconstruction rehabilitation
* Return-to-sport protocols
* Meniscus tear pathology & rehabilitation
* Conservative vs surgical ACL treatment
* Knee osteoarthritis evidence-based management
Important:â€¨PDFs are not included in the repository due to size and copyright.
To reproduce results, place any 10â€“15 clinical knee-related PDFs inside:
data/raw/
See docs/DATA_SOURCES.md for document descriptions.

ğŸ§  Prompt Versions
* v1: Zero-shot
* v2: Structured few-shot
* v3: Chain-of-thought
See docs/PROMPTS.md for full templates.

ğŸ“Š Evaluation
Latency, tokens, and answer quality were measured for 10 clinical queries across all prompt versions.
Includes:
* Total latency
* LLM-only latency
* Token usage
* Cost estimation
* Source citations
See docs/EVALUATION.md for complete results.

ğŸ§© Production Plan
See docs/PRODUCTION.md for:
* API architecture
* Error handling
* Monitoring & logging
* Safety constraints
* Deployment considerations
* Future improvements

âœ”ï¸ Summary
This project demonstrates a complete end-to-end RAG system:
* Local LLM deployment
* PDF ingestion pipeline
* Embedding & vector search
* Retrieval-augmented generation
* Prompt engineering
* Latency/cost evaluation
* Full documentation (DATA_SOURCES, PROMPTS, EVALUATION, PRODUCTION)
It can be extended into a full clinical-assistant API or UI.
